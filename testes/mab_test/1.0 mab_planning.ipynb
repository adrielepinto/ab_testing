{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7995d9c",
   "metadata": {},
   "source": [
    " # Business Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ada12",
   "metadata": {},
   "source": [
    "The company's Design team needs to choose between 2 or more options for web pages to be displayed to site visitors. Each page option has a different and unknown conversion rate and conversion probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b473cdf4",
   "metadata": {},
   "source": [
    "# Business Challange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb125d",
   "metadata": {},
   "source": [
    "The objective of choosing the option which one obtained the most conversion (reward).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186be99",
   "metadata": {},
   "source": [
    "# Solution Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57afed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T21:13:42.404936Z",
     "start_time": "2023-03-09T21:13:42.398900Z"
    }
   },
   "source": [
    "1.0 Apply the method IOT.\n",
    "Imput:\n",
    "- Dataset;\n",
    "- Business Plan;\n",
    "    \n",
    "Tesks:\n",
    "\n",
    "    - Hyphotesis Tests;\n",
    "    - Define the type of statistical inference method ( ANOVA, T-Test, Chi-Squared);\n",
    "    - Experiment Planning: Hyphotesis, Sample size, Expected Effect.\n",
    "\n",
    "Output:\n",
    "\n",
    "    - Text.  \n",
    "    \n",
    "- 1.0 Experiment Designer;\n",
    "- 2.0 Criate Hyphotesis to test;\n",
    "- 3.0 Define a metric;\n",
    "- 4.0 load the dataset;\n",
    "- 5.0 Data cleaning;\n",
    "- 6.0 Descriptive Analysis;\n",
    "- 7.0 Exploratory Data Anaysis;\n",
    "- 8.0 Hyphotesis Test( apply a test tecnic of statistical inference);\n",
    "- 9.0 Conclusion;\n",
    "- 10.0 Sugest which is the best variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd2c737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T01:21:29.190758Z",
     "start_time": "2023-09-01T01:21:25.363466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomAgent Prob Bandit 01: 30.0% - Prob Bandit 02: 80.0%\n",
      "\n",
      "RandomAgent AVG accumulated reward: :548.5065657003896%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RandomAgent( object ):\n",
    "    def __init__( self, prob_list ):\n",
    "        self.prob_list = prob_list\n",
    "\n",
    "    def pull( self, bandit_machine):\n",
    "        if np.random.random() < self.prob_list[bandit_machine]:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        return reward    \n",
    "\n",
    "# probability of having a positive result\n",
    "prob_list = [0.3, 0.8]\n",
    "\n",
    "#experiment parameters\n",
    "trials = 1000\n",
    "episodes = 200\n",
    "\n",
    "#agent\n",
    "bandit = RandomAgent( prob_list )\n",
    "\n",
    "prob_reward_array = np.zeros( len(prob_list))\n",
    "accumulated_reward_array = list()\n",
    "avg_accumulated_reward_array = list()\n",
    "for episode in range(episodes):\n",
    "    reward_array = np.zeros(len(prob_list))\n",
    "    bandit_array = np.full( len( prob_list), 1.0e-5 )\n",
    "    accumulated_reward = 0\n",
    "    for trial in range( trials ):\n",
    "            \n",
    "        #agent - choise\n",
    "        bandit_machine = np.random.randint(low=0, high=2, size=1)[0]\n",
    "\n",
    "        #agent - reward\n",
    "        reward = bandit.pull(bandit_machine)\n",
    "\n",
    "        #agent - keep reward\n",
    "        reward_array[bandit_machine] += reward\n",
    "        bandit_array[bandit_machine] += 1\n",
    "        accumulated_reward += reward\n",
    "\n",
    "    prob_reward_array += reward_array / bandit_array\n",
    "    accumulated_reward_array.append( accumulated_reward )\n",
    "    avg_accumulated_reward_array.append(np.mean(accumulated_reward_array))\n",
    "\n",
    "prob01 = 100*np.round(prob_reward_array[0] / episodes, 2)\n",
    "prob02 = 100*np.round(prob_reward_array[1] / episodes, 2)\n",
    "\n",
    "print(f'\\nRandomAgent Prob Bandit 01: {prob01}% - Prob Bandit 02: {prob02}%')\n",
    "print(f'\\nRandomAgent AVG accumulated reward: :{np.mean(avg_accumulated_reward_array)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7435a600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T01:21:30.856239Z",
     "start_time": "2023-09-01T01:21:29.194319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OmniscientAgent Prob Bandit 01: 0.0% - Prob Bandit 02: 80.0%\n",
      "\n",
      "OmniscientAgent AVG accumulated reward: :801.1820037398383%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OmniscientAgent( object ):\n",
    "    def __init__( self, prob_list ):\n",
    "        self.prob_list = prob_list\n",
    "\n",
    "    def pull( self, bandit_machine):\n",
    "        if np.random.random() < self.prob_list[bandit_machine]:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        return reward    \n",
    "\n",
    "# probability of having a positive result\n",
    "prob_list = [0.3, 0.8]\n",
    "\n",
    "# experiment parameters\n",
    "trials = 1000\n",
    "episodes = 200\n",
    "\n",
    "#agent\n",
    "bandit = OmniscientAgent( prob_list )\n",
    "\n",
    "prob_reward_array = np.zeros( len(prob_list))\n",
    "accumulated_reward_array = list()\n",
    "avg_accumulated_reward_array = list()\n",
    "for episode in range(episodes):\n",
    "    reward_array = np.zeros(len(prob_list))\n",
    "    bandit_array = np.full( len( prob_list), 1.0e-5 )\n",
    "    accumulated_reward = 0\n",
    "    for trial in range( trials ):\n",
    "            \n",
    "        #agent - choise\n",
    "        bandit_machine = np.argmax( prob_list )\n",
    "\n",
    "        #agent - reward\n",
    "        reward = bandit.pull(bandit_machine)\n",
    "\n",
    "        #agent - keep reward\n",
    "        reward_array[bandit_machine] += reward\n",
    "        bandit_array[bandit_machine] += 1\n",
    "        accumulated_reward += reward\n",
    "\n",
    "    prob_reward_array += reward_array / bandit_array\n",
    "    accumulated_reward_array.append( accumulated_reward )\n",
    "    avg_accumulated_reward_array.append(np.mean(accumulated_reward_array))\n",
    "\n",
    "prob01 = 100*np.round(prob_reward_array[0] / episodes, 2)\n",
    "prob02 = 100*np.round(prob_reward_array[1] / episodes, 2)\n",
    "\n",
    "print(f'\\nOmniscientAgent Prob Bandit 01: {prob01}% - Prob Bandit 02: {prob02}%')\n",
    "print(f'\\nOmniscientAgent AVG accumulated reward: :{np.mean(avg_accumulated_reward_array)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00004c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T01:21:31.378190Z",
     "start_time": "2023-09-01T01:21:30.859831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GreedyAgent Prob Bandit 01: 30.0% - Prob Bandit 02: 0.0%\n",
      "\n",
      " GreedyAgent AVG accumulated reward: :301.32999561482325%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GreedyAgent( object ):\n",
    "    def __init__( self, prob_list ):\n",
    "        self.prob_list = prob_list\n",
    "\n",
    "    def pull( self, bandit_machine):\n",
    "        if np.random.random() < self.prob_list[bandit_machine]:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        return reward    \n",
    "\n",
    "# probability of having a positive result\n",
    "prob_list = [0.3, 0.8]\n",
    "\n",
    "#experiment parameters\n",
    "trials = 1000\n",
    "episodes = 200\n",
    "eps_init = 0\n",
    "\n",
    "#agent\n",
    "bandit = GreedyAgent( prob_list )\n",
    "\n",
    "prob_reward_array = np.zeros( len(prob_list))\n",
    "accumulated_reward_array = list()\n",
    "avg_accumulated_reward_array = list()\n",
    "for episode in range(episodes):\n",
    "    reward_array = np.zeros(len(prob_list))\n",
    "    bandit_array = np.full( len( prob_list), 1.0e-5 )\n",
    "    accumulated_reward = 0\n",
    "    for trial in range( trials ):\n",
    "            \n",
    "        #agent - choise\n",
    "        if eps_init == 0: #exploração - escolhendo a primeira página\n",
    "            bandit_machine = 0 #página A\n",
    "        elif eps_init ==1: #exploração - escolhendo a seunda página\n",
    "            bandit_machine = 1 #página B\n",
    "        elif eps_init ==2: #exploitation - escolhendo a seunda página\n",
    "            prob_reward = reward_array / bandit_array\n",
    "            max_prob_reward = np.where( prob_reward == np.max( prob_reward ))[0]\n",
    "            bandit_machine = max_prob_reward[0]\n",
    "        else:\n",
    "            eps_init +=1\n",
    "        \n",
    "        #increasing eps_init\n",
    "        eps_init +=1\n",
    "\n",
    "        #agent - reward\n",
    "        reward = bandit.pull(bandit_machine)\n",
    "\n",
    "        #agent - keep reward\n",
    "        reward_array[bandit_machine] += reward\n",
    "        bandit_array[bandit_machine] += 1\n",
    "        accumulated_reward += reward\n",
    "\n",
    "    prob_reward_array += reward_array / bandit_array\n",
    "    accumulated_reward_array.append( accumulated_reward )\n",
    "    avg_accumulated_reward_array.append(np.mean(accumulated_reward_array))\n",
    "\n",
    "prob01 = 100*np.round(prob_reward_array[0] / episodes, 2)\n",
    "prob02 = 100*np.round(prob_reward_array[1] / episodes, 2)\n",
    "\n",
    "print(f'\\nGreedyAgent Prob Bandit 01: {prob01}% - Prob Bandit 02: {prob02}%')\n",
    "print(f'\\n GreedyAgent AVG accumulated reward: :{np.mean(avg_accumulated_reward_array)}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f0f10d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T01:21:34.140807Z",
     "start_time": "2023-09-01T01:21:31.383057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EpsGreedyAgent Prob Bandit 01: 22.0% - Prob Bandit 02: 10.0%\n",
      "\n",
      "EpsGreedyAgent AVG accumulated reward: :284.5164794808627%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EpsGreedyAgent( object ):\n",
    "    def __init__( self, prob_list ):\n",
    "        self.prob_list = prob_list\n",
    "\n",
    "    def pull( self, bandit_machine):\n",
    "        if np.random.random() < self.prob_list[bandit_machine]:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        return reward    \n",
    "\n",
    "# probability of having a positive result\n",
    "prob_list = [0.3, 0.25]\n",
    "\n",
    "#experiment parameters\n",
    "trials = 1000\n",
    "episodes = 200\n",
    "eps_init = 1\n",
    "decay = 0.39\n",
    "\n",
    "#decay eps\n",
    "eps_array = [(eps_init*(1-decay))**i for i in range( trials )]\n",
    "\n",
    "#agent\n",
    "bandit = EpsGreedyAgent( prob_list )\n",
    "\n",
    "prob_reward_array = np.zeros( len(prob_list))\n",
    "accumulated_reward_array = list()\n",
    "avg_accumulated_reward_array = list()\n",
    "for episode in range(episodes):\n",
    "    reward_array = np.zeros(len(prob_list))\n",
    "    bandit_array = np.full( len( prob_list), 1.0e-5 )\n",
    "    accumulated_reward = 0\n",
    "\n",
    "    for trial in range( trials ):\n",
    "            \n",
    "        #agent - escolha\n",
    "        eps = eps_array[ trial ]\n",
    "\n",
    "        if eps >= 0.15: #exploration and exploitation\n",
    "            #exploration\n",
    "            bandit_machine = np.random.randint( low=0, high=2, size=1)[0]\n",
    "\n",
    "            #exploitation\n",
    "        else:\n",
    "            prob_reward = reward_array / bandit_array\n",
    "            max_prob_reward = np.where(prob_reward == np.max( prob_reward))[0]\n",
    "            bandit_machine = max_prob_reward[0]\n",
    "\n",
    "        #agent - reward\n",
    "        reward = bandit.pull(bandit_machine)\n",
    "\n",
    "        #agent - keep[ reward\n",
    "        reward_array[bandit_machine] += reward\n",
    "        bandit_array[bandit_machine] += 1\n",
    "        accumulated_reward += reward\n",
    "\n",
    "    prob_reward_array += reward_array / bandit_array\n",
    "    accumulated_reward_array.append( accumulated_reward )\n",
    "    avg_accumulated_reward_array.append(np.mean(accumulated_reward_array))\n",
    "\n",
    "prob01 = 100*np.round(prob_reward_array[0] / episodes, 2)\n",
    "prob02 = 100*np.round(prob_reward_array[1] / episodes, 2)\n",
    "\n",
    "print(f'\\nEpsGreedyAgent Prob Bandit 01: {prob01}% - Prob Bandit 02: {prob02}%')\n",
    "print(f'\\nEpsGreedyAgent AVG accumulated reward: :{np.mean(avg_accumulated_reward_array)}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73aac62e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T01:21:34.151285Z",
     "start_time": "2023-09-01T01:21:34.144177Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "# from scipy.stats import beta\n",
    "\n",
    "# def reward_plot( success_array, failure_array):\n",
    "#     linestyle = [ '-', '--' ]\n",
    "\n",
    "#     x = np.linspace( 0, 1, 1002 )[1:-1]\n",
    "\n",
    "#     plt.clf()\n",
    "#     plt.xlim( 0, 1 )\n",
    "#     plt.ylim( 0, 30 )\n",
    "\n",
    "#     for a, b, ls in zip( success_array, failure_array, linestyle):\n",
    "#         dist = beta( a, b )\n",
    "\n",
    "#         plt.plot( x, dist.pdf(x), ls=ls, c= 'black', label='Alpha:{}, Beta:{}'.format( a, b ))\n",
    "#         plt.draw()\n",
    "#         plt.pause( 0.01 )\n",
    "#         plt.legend( loc=0 )\n",
    "\n",
    "# class ThompsonAgent( object ):\n",
    "#     def __init__( self, prob_list ):\n",
    "#         self.prob_list = prob_list\n",
    "\n",
    "#     def pull( self, bandit_machine):\n",
    "#         if np.random.random() < self.prob_list[bandit_machine]:\n",
    "#             reward = 1\n",
    "#         else:\n",
    "#             reward = 0\n",
    "\n",
    "#         return reward    \n",
    "\n",
    "# # probability of having a positive result\n",
    "# prob_list = [0.3, 0.25]\n",
    "\n",
    "# #experiment parameters\n",
    "# trials = 1000\n",
    "# episodes = 200\n",
    "\n",
    "# #agent\n",
    "# bandit = ThompsonAgent( prob_list )\n",
    "\n",
    "# prob_reward_array = np.zeros( len(prob_list))\n",
    "# accumulated_reward_array = list()\n",
    "# avg_accumulated_reward_array = list()\n",
    "# for episode in range(episodes):\n",
    "#     success_array = np.ones( len(prob_list))\n",
    "#     failure_array = np.full( len(prob_list), 1.0e-5)\n",
    "\n",
    "#     reward_array = np.zeros(len(prob_list))\n",
    "#     bandit_array = np.full( len( prob_list), 1.0e-5 )\n",
    "\n",
    "#     accumulated_reward = 0\n",
    "\n",
    "#     for trial in range( trials ):\n",
    "            \n",
    "#         #agent - choise\n",
    "#         prob_reward = np.random.beta( success_array, failure_array)\n",
    "#         bandit_machine = np.argmax( prob_reward )\n",
    "\n",
    "#         #agent - reward\n",
    "#         reward = bandit.pull(bandit_machine)\n",
    "\n",
    "#         if reward == 1:\n",
    "#             success_array[ bandit_machine ] += 1\n",
    "#         else:\n",
    "#             failure_array[ bandit_machine ] += 1\n",
    "\n",
    "#         #plot\n",
    "#         reward_plot( success_array, failure_array)\n",
    "\n",
    "#         #agent - keep reward  \n",
    "#         reward_array[bandit_machine] += reward\n",
    "#         bandit_array[bandit_machine] += 1\n",
    "#         accumulated_reward += reward\n",
    "\n",
    "#     prob_reward_array += reward_array / bandit_array\n",
    "#     accumulated_reward_array.append( accumulated_reward )\n",
    "#     avg_accumulated_reward_array.append(np.mean(accumulated_reward_array))\n",
    "\n",
    "# prob01 = 100*np.round(prob_reward_array[0] / episodes, 2)\n",
    "# prob02 = 100*np.round(prob_reward_array[1] / episodes, 2)\n",
    "\n",
    "# print(f'\\nProb Bandit 01: {prob01}% - Prob Bandit 02: {prob02}%')\n",
    "# print(f'\\nAVG accumulated reward: :{np.mean(avg_accumulated_reward_array)}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263b777d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T01:21:36.237098Z",
     "start_time": "2023-09-01T01:21:34.155410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bayesian_inference(data):\n",
    "    N_mc = 10000\n",
    "    proba_b_better_a = []\n",
    "    expected_loss_a = []\n",
    "    expected_loss_b = []\n",
    "    for day in range(len(data)):\n",
    "            \n",
    "        u_a, var_a = stats.beta.stats( a= 1+ data.loc[day, 'acc_clicks_A'],\n",
    "                                    b= 1 + (data.loc[day, 'acc_visits_A'] - data.loc[day, 'acc_clicks_A']),\n",
    "                                    moments= 'mv')\n",
    "\n",
    "        u_b, var_b = stats.beta.stats( a= 1+ data.loc[day, 'acc_clicks_B'],\n",
    "                                    b= 1 + (data.loc[day, 'acc_visits_B'] - data.loc[day, 'acc_clicks_B']),\n",
    "                                    moments= 'mv')\n",
    "\n",
    "        # Disbrution of normal sampling A\n",
    "        x_a = np.random.normal( loc = u_a,\n",
    "                                scale = 1.25*np.sqrt( var_a ),\n",
    "                                size = N_mc)\n",
    "\n",
    "        # Disbrution of normal sampling B\n",
    "        x_b = np.random.normal( loc = u_b,\n",
    "                                scale = 1.25*np.sqrt( var_b ),\n",
    "                                size = N_mc)\n",
    "\n",
    "        #Disbrution beta of the page A\n",
    "        fa = stats.beta.pdf( x_a,\n",
    "                            a = 1 + data.loc[day, 'acc_clicks_A'],\n",
    "                            b = 1 + (data.loc[day, 'acc_visits_A'] - data.loc[day, 'acc_clicks_A']))\n",
    "\n",
    "        #Disbrution beta of the page B\n",
    "        fb = stats.beta.pdf( x_b,\n",
    "                            a = 1 + data.loc[day, 'acc_clicks_B'],\n",
    "                            b = 1 + (data.loc[day, 'acc_visits_B'] - data.loc[day, 'acc_clicks_B']))\n",
    "\n",
    "        #Disbrution beta of the page A\n",
    "        ga = stats.norm.pdf( x_a,\n",
    "                            loc = u_a,\n",
    "                            scale = 1.25*np.sqrt(var_a))\n",
    "\n",
    "        #Normal Distribution of page B\n",
    "        gb = stats.norm.pdf( x_b,\n",
    "                            loc = u_b,\n",
    "                            scale = 1.25*np.sqrt(var_b))\n",
    "\n",
    "        # Beta/Normal\n",
    "        y = (fa*fb) / (ga*gb)\n",
    "\n",
    "        # Only values where B is > than A\n",
    "        yb = y[x_b >= x_a]\n",
    "\n",
    "        #probability of  B to be > than A\n",
    "        p = ( 1 / N_mc)*np.sum(yb)\n",
    "\n",
    "        # Error to assum   B is better than   A\n",
    "        expected_loss_A = ( 1/N_mc ) * np.sum(((x_b - x_a)*y)[x_b >= x_a]) \n",
    "        expected_loss_B = ( 1/N_mc ) * np.sum(((x_a - x_b)*y)[x_a >= x_b]) \n",
    "\n",
    "        proba_b_better_a.append( p )\n",
    "        expected_loss_a.append(expected_loss_A)\n",
    "        expected_loss_b.append(expected_loss_B)\n",
    "\n",
    "    return proba_b_better_a, expected_loss_a, expected_loss_b\n",
    "\n",
    "def animate(i):\n",
    "    data = pd.read_csv('data_experiment.csv')\n",
    "\n",
    "    #dtypes\n",
    "    data['click'] = data['click'].astype(int)\n",
    "    data['visit'] = data['visit'].astype(int)\n",
    "\n",
    "    # pivot table\n",
    "    #data = data.drop(columns={' '})\n",
    "    data = data.reset_index().rename(columns={\"index\": \"day\"})\n",
    "    data = data.pivot(index='day', columns='group', values=['click', 'visit']).fillna(0)\n",
    "    data.columns = ['click_control', 'click_treatment', 'visit_control', 'visit_treatment']\n",
    "    data = data.reset_index( drop=True )\n",
    "    #data = data[['click_control', 'click_treatment', 'visit_control', 'visit_treatment']]\n",
    "\n",
    "    data['acc_visits_A'] = np.cumsum(data['visit_control'])\n",
    "    data['acc_visits_B'] = np.cumsum(data['visit_treatment'])\n",
    "\n",
    "    data['acc_clicks_A'] = np.cumsum(data['click_control'])\n",
    "    data['acc_clicks_B'] = np.cumsum(data['click_treatment'])\n",
    "\n",
    "    #inference bayesian\n",
    "    proba_b_better_a, expected_loss_a, expected_loss_b = bayesian_inference(data)\n",
    "\n",
    "    x1 = np.arange( len(proba_b_better_a))\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.plot( x1, proba_b_better_a, label='Probability B better A')\n",
    "    plt.plot( x1, expected_loss_a, label='Risk choosing A')\n",
    "    plt.plot( x1, expected_loss_b, label='Risk choosing B')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "ani = FuncAnimation(plt.gcf(), animate, interval=1000)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6738539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T01:21:36.243690Z",
     "start_time": "2023-09-01T01:21:36.239843Z"
    }
   },
   "outputs": [],
   "source": [
    "df_reward = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e75c787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T01:21:36.252560Z",
     "start_time": "2023-09-01T01:21:36.246470Z"
    }
   },
   "outputs": [],
   "source": [
    "df_reward['Agente'] =['Random', 'Greedy', 'Omnisciente', 'Epson Greedy' , 'Thampson']\n",
    "df_reward['Rewards %'] = [ 552, 800, 798, 285, 795 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6351190b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T01:21:36.265548Z",
     "start_time": "2023-09-01T01:21:36.255344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agente</th>\n",
       "      <th>Rewards %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greedy</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Omnisciente</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Epson Greedy</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thampson</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Agente  Rewards %\n",
       "0        Random        552\n",
       "1        Greedy        800\n",
       "2   Omnisciente        798\n",
       "3  Epson Greedy        285\n",
       "4      Thampson        795"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reward.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e460a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f884165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b7e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460b675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64f649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1faa35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e440e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962de50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
